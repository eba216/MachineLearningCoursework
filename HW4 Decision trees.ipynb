{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/baeza/OneDrive/Desktop/CS 760 Fall 2020/titanic_data.csv\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class(pclass):\n",
    "    if pclass<2:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "df[\"Pclass\"]=df[\"Pclass\"].apply(check_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_adult(age):\n",
    "    if age<=15:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "df[\"Age\"]=df[\"Age\"].apply(check_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fam(num):\n",
    "    if num>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df[\"Siblings/Spouses Aboard\"]=df[\"Siblings/Spouses Aboard\"].apply(check_fam)\n",
    "df[\"Parents/Children Aboard\"]=df[\"Parents/Children Aboard\"].apply(check_fam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fare(num):\n",
    "    if num<10:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "df[\"Fare\"]=df[\"Fare\"].apply(check_fare)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "\n",
    "# takes in data x and computes entropy of column j \n",
    "def entropy(x: np.ndarray, j: int ) -> float:\n",
    "    p=0\n",
    "    for row in x:\n",
    "        if row[j] == 1:\n",
    "            p+=1\n",
    "    p = p/len(x) \n",
    "    term_1 = -p*log(p, 2) if p> 0 else 0 \n",
    "    term_2 = - (1-p)*log(1-p,2) if (1-p) > 0 else 0  \n",
    "    return term_1 + term_2\n",
    "\n",
    "# takes in data x and and column j   \n",
    "# assumes label is first column of x \n",
    "def cond_entropy(x: np.ndarray, j: int) -> float:\n",
    "    p00, p01, p10, p11 = 0,0,0,0\n",
    "    y0, y1 = 0,0\n",
    "    for row in x:\n",
    "        if row[0] == 0 and row[j] == 0:\n",
    "            p00+=1\n",
    "        elif row[0] == 0 and row[j] == 1:\n",
    "            p01+=1\n",
    "            y1+=1\n",
    "        elif row[0] == 1 and row[j] == 0:\n",
    "            p10+=1\n",
    "        else:\n",
    "            p11+=1\n",
    "            y1+=1\n",
    "            \n",
    "    n=len(x)\n",
    "    y1 = y1/n\n",
    "    y0 =1-y1\n",
    "    if (y1 == 0 or y0 == 0):\n",
    "        return 0\n",
    "    \n",
    "    p00, p01, p10, p11 =  p00/n, p01/n, p10/n, p11/n  \n",
    "    \n",
    "    term_1 =  -p00*log(p00/y0, 2) if p00 > 0 else 0 \n",
    "    term_2 =  -p01*log(p01/y0, 2) if p01 > 0 else 0\n",
    "    term_3 =  -p10*log(p10/y1, 2) if p10 > 0 else 0\n",
    "    term_4 =  -p11*log(p11/y1, 2) if p11 > 0 else 0\n",
    "\n",
    "    return term_1 + term_2 + term_3 + term_4 \n",
    "    \n",
    "# takes in data x and and column j   \n",
    "# assumes label is first column of x \n",
    "def mut_info(x: np.ndarray, j: int) -> float:\n",
    "    return entropy(x,j) - cond_entropy(x,j)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information of Pclass is 0.12852990753894167\n",
      "Mutual information of Sex is 0.2199535166853407\n",
      "Mutual information of Age is 0.3958215592539193\n",
      "Mutual information of Siblings/Spouses is 0.023456210552088463\n",
      "Mutual information of Parents/Children is 0.09012072631532175\n",
      "Mutual information of Fare is 0.06571482491715952\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mutual information of Pclass is {mut_info(data,1)}\")\n",
    "print(f\"Mutual information of Sex is {mut_info(data,2)}\")\n",
    "print(f\"Mutual information of Age is {mut_info(data,3)}\")\n",
    "print(f\"Mutual information of Siblings/Spouses is {mut_info(data,4)}\")\n",
    "print(f\"Mutual information of Parents/Children is {mut_info(data,5)}\")\n",
    "print(f\"Mutual information of Fare is {mut_info(data,6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, value,left=None, right=None, feature=0):\n",
    "        self.value = value \n",
    "        self.feature = feature\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    \n",
    "    def __str__(self, level=0):\n",
    "        ret = \"\"\n",
    "        if self is None:\n",
    "            ret+=\" \"\n",
    "        if self.value is not None:\n",
    "            ret += ( \"_\\t\"*level + str(self.value)+ \"\\n\" ) if self.value is not None else \" \"\n",
    "        else:\n",
    "            return \"\"\n",
    "        left, right = self.left, self.right\n",
    "        \n",
    "        ret += right.__str__(level+1) if right else \"\"\n",
    "        \n",
    "        ret += left.__str__(level+1) if left else \"\"\n",
    "        \n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def same_label(S: np.ndarray)-> bool:    \n",
    "    label = S[0][0]\n",
    "    if label == None:\n",
    "        return True\n",
    "    for s in S:\n",
    "        if s[0] != label:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def major_label(S: np.ndarray)-> float:\n",
    "    maj = 0\n",
    "    for s in S:\n",
    "        if s[0] == 1:\n",
    "            maj +=1\n",
    "    return 1.0 if maj >= len(S) - maj else 0.0  \n",
    "\n",
    "\n",
    "# Implementation of the ID3 algorithm to build decision tree \n",
    "# traning set S, feature subset A\n",
    "def build_tree(S : np.ndarray, A: list)->Node:\n",
    "    # Stoping criteria\n",
    "    \n",
    "    if len(S) == 0:\n",
    "        return Node(None, None, None,0)\n",
    "    # if all samples are labeled by 1 (or 0), return a leaf 1 (or 0)\n",
    "    if same_label(S):\n",
    "        value = float(S[0][0])\n",
    "        return Node(value, None, None,0)\n",
    "        \n",
    "    \n",
    "    # if A is empty, return a leaf whose value =\n",
    "    # majority of labels in S\n",
    "    if len(A) == 0:\n",
    "        return Node(major_label(S), None, None,0)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # let j = argmax_{i \\in A} mut_info(S,i)\n",
    "        info = dict()\n",
    "        for i in A:\n",
    "            info[i] = mut_info(S,i)\n",
    "        j = sorted(info.keys(),key=lambda k: info[k])[-1]\n",
    "        \n",
    "        # if all samples in S have same label\n",
    "        if same_label(S):\n",
    "            value = float(S[0][0])\n",
    "            if value is None:\n",
    "                return  Node(value, None, None, 0)\n",
    "            return Node(S[0][0], None, None, 0)\n",
    "        \n",
    "        else:\n",
    "            #Sm_j = {(x,y) in S : x_j = m } \n",
    "            S0_j = S[S[:,j]==0]\n",
    "            S1_j = S[S[:,j]==1]\n",
    "            \n",
    "            A_j = [k for k in A if k != j]\n",
    "            T_1 = build_tree(S1_j, A_j) if len(S1_j) > 0 else None\n",
    "            T_2 = build_tree(S0_j, A_j) if len(S0_j) > 0 else None\n",
    "            \n",
    "            #This dictionary is only for pretty printing purposes\n",
    "            categories = dict({1: (\"Pclass\", 2), 2:(\"Sex\", 1), 3 :(\"Age\", 18),\\\n",
    "                              4:(\"Sibs/Spse\", 1),\\\n",
    "                               5:(\"Par/Child\", 1), 6:(\"Fare\",35),\\\n",
    "                               0: (\"WHY are we\", \"here?\")})\n",
    "            \n",
    "            #return Node(f\" {categories[j][0]} < {categories[j][1]} \", T_2, T_1, feature=j)\n",
    "            return Node(f\" x_{j} < 0.5 \", T_2, T_1, feature=j)\n",
    "    \n",
    "    \n",
    "\n",
    "# Given a decision tree, get its prediction \n",
    "def get_DT_prediction(DT: Node, x: np.array)-> float:\n",
    "    current_node = DT\n",
    "    x_temp = np.array(x).ravel()\n",
    "    j = current_node.feature\n",
    "    while j > 0:\n",
    "        if x_temp[j] < 0.5:\n",
    "            if current_node.left is not None:\n",
    "                current_node = current_node.left\n",
    "            else:\n",
    "                break\n",
    "            j = current_node.feature\n",
    "            continue\n",
    "        else:\n",
    "            if current_node.right is not None:\n",
    "                current_node = current_node.right\n",
    "            else:\n",
    "                break\n",
    "            j = current_node.feature\n",
    "            continue\n",
    "    return current_node.value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'string' (str) to file 'example.txt'.\n",
      "Writing 'DT.__str__()' (str) to file 'example.txt'.\n"
     ]
    }
   ],
   "source": [
    "A = [i for i in range(1, len(data[0]))]\n",
    "DT = build_tree(data, A)\n",
    "#print(\"If condition is true, go left \\n\")\n",
    "#print(DT)\n",
    "string = \"If condition is true, go \\\"left\\\" \\n \\n\"\n",
    "%store string > example.txt\n",
    "%store DT.__str__() >> example.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from random import randrange\n",
    "\n",
    "# Builds a random forest using our decision tree implementation\n",
    "# Has two modes: \"80\" which uses a random subset of 80% of the data \n",
    "# for each tree, and \"features\" which excludes one feature for each tree\n",
    "def build_forest(data: np.ndarray, size: int ,mode: str=\"80\") -> List[Node]:\n",
    "    forest = []\n",
    "    data_copy = data\n",
    "    \n",
    "    for i in range(size):\n",
    "        # generate random sample of 80% of data \n",
    "        if mode==\"80\":\n",
    "            for j in range(len(data)//5):\n",
    "                data_copy = data\n",
    "                # select a random element and determine its index\n",
    "                index = randrange(len(data_copy))\n",
    "                elem = data_copy[index] \n",
    "                # delete it so it is not chosen again \n",
    "                data_copy = np.delete(data_copy, index, axis=0)\n",
    "            \n",
    "            A = [k for k in range(1, len(data_copy[0]))]\n",
    "            tree = build_tree(data_copy, A) \n",
    "            forest.append(tree)\n",
    "        \n",
    "        # generate forest by excluding one of every feature\n",
    "        else:\n",
    "            data_copy = data\n",
    "            \n",
    "            if(size != len(data_copy[0])-1):\n",
    "                print(\"Size of forest must equal number of features\")\n",
    "                return\n",
    "            # delete feature i+1 since feature at index 0 is survival  \n",
    "            #data_copy = np.delete(data_copy,i+1, axis=1)\n",
    "            A = [k for k in range(1, len(data_copy[0])) if k != i+1]\n",
    "            tree = build_tree(data_copy, A) \n",
    "            forest.append(tree)\n",
    "        \n",
    "    \n",
    "    return forest\n",
    "\n",
    "# prints all the trees in the forest \n",
    "def print_forest(forest: List[Node]):\n",
    "    for tree in forest:\n",
    "        print(f\"Tree{ forest.index(tree)+ 1} \\n\\n\")\n",
    "        print(tree)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "\n",
    "# stirng representation of all the trees in the forest \n",
    "def forest_to_str(forest: List[Node]):\n",
    "    ret =\"\"\n",
    "    for tree in forest:\n",
    "        ret+= f\"Tree{ forest.index(tree)+ 1} \\n\\n\"\n",
    "        ret+= tree.__str__() + \"\\n\"\n",
    "    return ret \n",
    "\n",
    "\n",
    "#Given a random forest, get its prediction \n",
    "def get_forest_prediction(forest: List[Node], x: np.array) -> float:\n",
    "    results = []\n",
    "    for tree in forest:\n",
    "        results.append(get_DT_prediction(tree,x))\n",
    "    \n",
    "    return max(set(results),key=results.count)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "# split data into k \n",
    "def k_fold_split(data: np.ndarray, k: int)-> np.ndarray:\n",
    "    data_split = []\n",
    "    data_copy = data\n",
    "    subset_size = len(data_copy)//k\n",
    "    \n",
    "    # save k subsets  \n",
    "    for i in range(k):\n",
    "        subset = []\n",
    "        # add elements to subset.\n",
    "        while len(subset) < subset_size and len:\n",
    "            # select a random element and determine its index\n",
    "            index = randrange(len(data_copy))\n",
    "            elem = data_copy[index]\n",
    "            # save the randomly selected line and  \n",
    "            # delete it so it is not chosen again \n",
    "            subset.append(elem)\n",
    "            data_copy = np.delete(data_copy, index, axis=0)\n",
    "        # save subset\n",
    "        data_split.append(np.asarray(subset))\n",
    "        \n",
    "    return data_split\n",
    "\n",
    "\n",
    "#\n",
    "def k_fold_cv_DT(data: np.ndarray, k: int, mode: str=\"tree\", forest_size: int= 1)-> np.ndarray:\n",
    "    k_folds = k_fold_split(data, k)\n",
    "    results = []\n",
    "    \n",
    "    \n",
    "    # detemine training sets and test sets\n",
    "    for i in range(k):\n",
    "        cv = np.array([])\n",
    "        # get all fold indicies and remove one for testing\n",
    "        train_folds = [l for l in range(k)]\n",
    "        train_folds.pop(i)\n",
    "        \n",
    "        # collect remaining folds into a data set.   \n",
    "        for j in train_folds:\n",
    "            # combine remaining folds into training dataset\n",
    "            # set cv to be the first remaining fold, \n",
    "            # then append the rest\n",
    "            if j == train_folds[0]:\n",
    "                cv = k_folds[j]\n",
    "            else:\n",
    "                cv = np.concatenate((cv, k_folds[j]), axis=0)\n",
    "       \n",
    "        # apply models\n",
    "        if mode == 'tree':    \n",
    "            A = [i for i in range(1, len(data[0]))]\n",
    "            DT = build_tree(cv, A) \n",
    "            test_predicts = [get_DT_prediction(DT,np.array(row)) for row in k_folds[i]] \n",
    "        elif mode == 'forest_80':    \n",
    "            RF = build_forest(cv, forest_size, mode =\"80\") \n",
    "            test_predicts = [get_forest_prediction(RF,np.array(row)) for row in k_folds[i]] \n",
    "        elif mode == 'forest_features':    \n",
    "            RF = build_forest(cv, forest_size, mode =\"features\") \n",
    "            test_predicts = [get_forest_prediction(RF,np.array(row)) for row in k_folds[i]]\n",
    "            \n",
    "        #calculate accuracy\n",
    "        acc = float(reduce(np.add, list(map(lambda r: 1 if r[0]==r[1][0] else 0, zip(test_predicts, k_folds[i][:])))))\n",
    "        results.append(acc/len(test_predicts)) \n",
    "    \n",
    "    return sum(results)/len(results)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold validation for our decision tree classifier is 0.7852272727272728\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "kcv = k_fold_cv_DT(data,k, mode=\"tree\")\n",
    "print(f\"{k}-fold validation for our decision tree classifier is {kcv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Decision tree gives 1.0\n"
     ]
    }
   ],
   "source": [
    "# our implementation assumes a vector of length 7\n",
    "# the first value is not used when checking decision tree\n",
    "x_new = np.array([21, 1, 0, 19, 1, 0, 35]) \n",
    "print(f\" Decision tree gives {get_DT_prediction(DT,x_new)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest predicts 1.0 in mode 80\n",
      "Writing 'string2' (str) to file 'example2.txt'.\n",
      "Writing 'forest_to_str(RF)' (str) to file 'example2.txt'.\n"
     ]
    }
   ],
   "source": [
    "RF = build_forest(data, 5, mode=\"80\")\n",
    "print(f\"Random forest predicts {get_forest_prediction(RF, x_new)} in mode 80\")\n",
    "#print_forest(RF)\n",
    "\n",
    "string2 = \"Random forest predicts in mode 80 \\n \\n\"\n",
    "%store string2 > example2.txt\n",
    "%store forest_to_str(RF) >> example2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest predicts 1.0 in mode features\n",
      "Writing 'string3' (str) to file 'example3.txt'.\n",
      "Writing 'forest_to_str(RF2)' (str) to file 'example3.txt'.\n"
     ]
    }
   ],
   "source": [
    "RF2 = build_forest(data, 6, mode=\"features\")\n",
    "print(f\"Random forest predicts {get_forest_prediction(RF2, x_new)} in mode features\")\n",
    "#print_forest(RF2)\n",
    "\n",
    "string3 = \"Random forest predicts in mode features \\n \\n\"\n",
    "%store string3 > example3.txt\n",
    "%store forest_to_str(RF2) >> example3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold validation for our random forest classifier which uses 80% random data is 0.778409090909091\n"
     ]
    }
   ],
   "source": [
    "kcv2 = k_fold_cv_DT(data,k, mode=\"forest_80\", forest_size=5)\n",
    "print(f\"{k}-fold validation for our random forest classifier \\\n",
    "which uses 80% random data is {kcv2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold validation for our random forest classifier which excludes each feature once is 0.7943181818181818\n"
     ]
    }
   ],
   "source": [
    "kcv3 = k_fold_cv_DT(data,k, mode=\"forest_features\",forest_size=6)\n",
    "print(f\"{k}-fold validation for our random forest classifier \\\n",
    "which excludes each feature once is {kcv3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
